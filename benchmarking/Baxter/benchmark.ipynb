{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "Resave data as a set of tiff files in order to match Cell Tracking Challenge conventions which are expected by EmbedTrack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import imwrite\n",
    "\n",
    "from deepcell.applications import NuclearSegmentation\n",
    "from deepcell_tracking.isbi_utils import trk_to_isbi\n",
    "from deepcell_tracking.trk_io import load_trks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = '../../data/test.trks'\n",
    "data_dir = 'data'\n",
    "raw_dir = os.path.join(data_dir, 'raw')\n",
    "seg_gt_dir = os.path.join(raw_dir, 'Analysis/Segmentation_GT')\n",
    "seg_dc_dir = os.path.join(raw_dir, 'Analysis/Segmentation_DeepCell')\n",
    "gt_dir = os.path.join(data_dir, 'GT')\n",
    "\n",
    "for d in [raw_dir, seg_gt_dir, seg_dc_dir, gt_dir]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test split of the tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_trks(source_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the DeepCell nuclear segmentation model to test the algorithm on predicted instead of ground truth segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:37:44.248981: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 00:37:44.915438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10415 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "app = NuclearSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_without_zeros(app, X):\n",
    "    \"\"\"Remove zero padding to avoid adverse effects on model performance\"\"\"\n",
    "    # Calculate position of padding based on first frame\n",
    "    # Assume that padding is in blocks on the edges of image\n",
    "    good_rows = np.where(X.any(axis=0))[0]\n",
    "    good_cols = np.where(X.any(axis=1))[0]\n",
    "\n",
    "    slc = (\n",
    "        slice(good_cols[0], good_cols[-1] + 1),\n",
    "        slice(good_rows[0], good_rows[-1] + 1),\n",
    "    )\n",
    "\n",
    "    y_pred = np.zeros_like(X)\n",
    "    y_pred[slc] = app.predict(X[slc])\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each batch of the test split to the standard ISBI format which is compatible with most of the models that we will test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 00:37:57.263247: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    }
   ],
   "source": [
    "for batch_no in range(len(data['lineages'])):\n",
    "    # Build subdirectories for data\n",
    "    raw_subdir = os.path.join(raw_dir, '{:03}'.format(batch_no + 1))\n",
    "    gt_subdir = os.path.join(gt_dir, '{:03}'.format(batch_no + 1))\n",
    "    seg_gt_subdir = os.path.join(seg_gt_dir, '{:03}'.format(batch_no + 1))\n",
    "    seg_dc_subdir = os.path.join(seg_dc_dir, '{:03}'.format(batch_no + 1))\n",
    "    \n",
    "    # Create directories if needed\n",
    "    for d in (raw_subdir, gt_subdir, seg_gt_subdir, seg_dc_subdir):\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "                \n",
    "    # Pull out relevant data for this batch\n",
    "    X = data['X'][batch_no]\n",
    "    y = data['y'][batch_no]\n",
    "    lineages = data['lineages'][batch_no]\n",
    "    \n",
    "    # Need to translate lineages and adjust images to match restrictive ISBI format\n",
    "    # Prepare output txt\n",
    "    text_file = os.path.join(gt_subdir, 'man_track.txt')\n",
    "    df = trk_to_isbi(lineages)\n",
    "    df.to_csv(text_file, sep=' ', header=False)\n",
    "    \n",
    "    # Determine which frames are zero padding\n",
    "    frames = np.sum(y, axis=(1,2)) # True if image not blank\n",
    "    good_frames = np.where(frames)[0]\n",
    "    # We assume here that the empty frames are at the end of the movie (padding rather than skipped)\n",
    "    movie_len = len(good_frames)\n",
    "    \n",
    "    # Save each frame of the movie as an individual tif\n",
    "    channel = 0 # These images should only have one channel\n",
    "    for i in range(movie_len):\n",
    "        name_raw = os.path.join(raw_subdir, 't{:03}.tif'.format(i))\n",
    "        name_seg_gt = os.path.join(seg_gt_subdir, 't{:03}.tif'.format(i))\n",
    "        name_seg_dc = os.path.join(seg_dc_subdir, 't{:03}.tif'.format(i))\n",
    "        name_gt = os.path.join(gt_subdir, 't{:03}.tif'.format(i))\n",
    "        \n",
    "        # Generate deepcell prediction\n",
    "        pred = predict_without_zeros(app, X[i:i+1, ..., channel:channel+1])\n",
    "        \n",
    "        imwrite(name_raw, X[i, ..., channel])\n",
    "        imwrite(name_seg_gt, y[i, ..., channel].astype('uint16'))\n",
    "        imwrite(name_seg_dc, pred.astype('uint16'))\n",
    "        imwrite(name_gt, y[i, ..., channel].astype('uint16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tracking\n",
    "\n",
    "The steps for tracking will be performed in Matlab and the Baxter Algorithm GUI. You will need access to Matlab 2019b. The instructions below outline the general workflow for generating benchmarking results using the Baxter algorithm. However additional support for using the software is available in the user guide located in the KTH-SE folder (`KTH-SE/UserGuide/UserGuide.pdf`).\n",
    "\n",
    "## Part 1 - Setup\n",
    "1. Open the KTH-SE folder in Matlab\n",
    "2. Open `BaxterAlgorithms.m` in the Matlab editor and then hit Run. This should open a GUI.\n",
    "3. Within the GUI, select `Files > Open experiment > Browse...`. Navigate to the `data/raw` folder located within this Baxter folder.\n",
    "4. Ensure that all files are selected in the list on the right hand side of the GUI.\n",
    "## Part 2 - GT Segmentations\n",
    "5. Select `Settings > Load Settings (Browse for files)`. Navigate to `Settings-SegmentationGT.csv` within the Baxter folder. In the following prompts, ensure that segmentations are applied to all images.\n",
    "6. Select `Automated > Track`. In the pop-up window, change the `Save Version` to \"GT\" and press `Start`. \n",
    "7. Select `File > Export tracks to CTC format > RES tracks` and follow the prompts in order to export the tracking results to the standard CTC format. Make sure to select the \"GT\" version for export.\n",
    "## Part 3 - DeepCell Segmentations\n",
    "8. Select `Settings > Load Settings (Browse for files)`. Navigate to `Settings-SegmentationDeepCell.csv` within the Baxter folder. In the following prompts, ensure that segmentations are applied to all images.\n",
    "6. Select `Automated > Track`. In the pop-up window, change the `Save Version` to \"DeepCell\" and press `Start`. \n",
    "7. Select `File > Export tracks to CTC format > RES tracks` and follow the prompts in order to export the tracking results to the standard CTC format. Make sure to select the \"DeepCell\" version for export.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from deepcell_tracking.metrics import TrackingMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/GT'\n",
    "export_gt_dir = 'data/raw/Analysis/CellDataGT/RES'\n",
    "export_dc_dir = 'data/raw/Analysis/CellDataDeepCell/RES'\n",
    "\n",
    "data_ids = os.listdir(data_dir)\n",
    "\n",
    "node_match_threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed node 21_42 division completely\n",
      "missed node 37_35 division completely\n",
      "missed node 38_5 division completely\n",
      "missed node 43_4 division completely\n",
      "missed node 50_42 division completely\n",
      "missed node 5_6 division completely\n",
      "missed node 10_66 division completely\n",
      "missed node 15_66 division completely\n",
      "missed node 25_57 division completely\n",
      "30_37 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 55_27 division completely\n",
      "missed node 76_44 division completely\n",
      "missed node 94_36 division completely\n",
      "missed node 104_34 division completely\n",
      "missed node 112_6 division completely\n",
      "missed node 118_0 division completely\n",
      "missed node 121_42 division completely\n",
      "missed node 125_22 division completely\n",
      "missed node 127_51 division completely\n",
      "missed node 128_43 division completely\n",
      "missed node 140_10 division completely\n",
      "missed node 144_28 division completely\n",
      "missed node 147_33 division completely\n",
      "missed node 160_64 division completely\n",
      "missed node 163_66 division completely\n",
      "missed node 167_7 division completely\n",
      "missed node 179_68 division completely\n",
      "missed node 1_29 division completely\n",
      "missed node 20_38 division completely\n",
      "missed node 15_17 division completely\n",
      "missed node 19_20 division completely\n",
      "22_5 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 29_17 division completely\n",
      "missed node 59_10 division completely\n",
      "missed node 60_34 division completely\n",
      "76_7 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 79_9 division completely\n",
      "missed node 80_9 division completely\n",
      "missed node 82_17 division completely\n",
      "missed node 83_18 division completely\n",
      "corrected division 79_9 as a frameshift division not an error\n",
      "corrected division 82_17 as a frameshift division not an error\n",
      "missed node 1_48 division completely\n",
      "missed node 26_25 division completely\n",
      "missed node 4_26 division completely\n",
      "missed node 5_53 division completely\n",
      "missed node 8_42 division completely\n",
      "missed node 12_31 division completely\n",
      "missed node 14_35 division completely\n",
      "missed node 16_30 division completely\n",
      "18_16 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 22_24 division completely\n",
      "missed node 36_55 division completely\n",
      "missed node 45_50 division completely\n",
      "74_29 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "79_28 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "80_25 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 89_36 division completely\n",
      "missed node 91_51 division completely\n",
      "missed node 103_42 division completely\n",
      "missed node 106_37 division completely\n",
      "missed node 119_22 division completely\n",
      "missed node 122_36 division completely\n",
      "missed node 123_38 division completely\n",
      "missed node 10_13 division completely\n",
      "missed node 11_68 division completely\n",
      "missed node 27_14 division completely\n",
      "missed node 49_41 division completely\n",
      "missed node 50_40 division completely\n",
      "missed node 57_10 division completely\n",
      "missed node 58_36 division completely\n",
      "missed node 60_0 division completely\n",
      "corrected division 10_13 as a frameshift division not an error\n",
      "missed node 18_9 division completely\n",
      "missed node 21_42 division completely\n",
      "missed node 37_35 division completely\n",
      "missed node 38_5 division completely\n",
      "missed node 41_26 division completely\n",
      "missed node 43_4 division completely\n",
      "missed node 50_42 division completely\n",
      "missed node 54_28 division completely\n",
      "missed node 73_5 division completely\n",
      "missed node 5_6 division completely\n",
      "missed node 10_66 division completely\n",
      "missed node 15_66 division completely\n",
      "missed node 16_9 division completely\n",
      "missed node 22_56 division completely\n",
      "missed node 25_57 division completely\n",
      "missed node 30_37 division completely\n",
      "missed node 51_28 division completely\n",
      "missed node 55_27 division completely\n",
      "missed node 78_45 division completely\n",
      "missed node 80_61 division completely\n",
      "missed node 94_36 division completely\n",
      "missed node 95_52 division completely\n",
      "missed node 97_60 division completely\n",
      "missed node 104_34 division completely\n",
      "missed node 115_45 division completely\n",
      "missed node 118_0 division completely\n",
      "missed node 121_42 division completely\n",
      "missed node 125_22 division completely\n",
      "missed node 126_61 division completely\n",
      "missed node 127_51 division completely\n",
      "missed node 128_43 division completely\n",
      "missed node 132_23 division completely\n",
      "missed node 133_24 division completely\n",
      "135_25 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 140_10 division completely\n",
      "missed node 141_35 division completely\n",
      "missed node 142_17 division completely\n",
      "missed node 144_28 division completely\n",
      "missed node 147_33 division completely\n",
      "missed node 148_59 division completely\n",
      "missed node 163_66 division completely\n",
      "missed node 167_7 division completely\n",
      "missed node 179_68 division completely\n",
      "missed node 185_49 division completely\n",
      "missed node 1_29 division completely\n",
      "missed node 3_23 division completely\n",
      "missed node 20_38 division completely\n",
      "missed node 29_29 division completely\n",
      "missed node 10_19 division completely\n",
      "missed node 15_17 division completely\n",
      "missed node 19_20 division completely\n",
      "missed node 22_5 division completely\n",
      "missed node 29_17 division completely\n",
      "missed node 59_10 division completely\n",
      "missed node 60_34 division completely\n",
      "missed node 76_7 division completely\n",
      "missed node 79_9 division completely\n",
      "80_9 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 82_17 division completely\n",
      "missed node 83_18 division completely\n",
      "missed node 1_48 division completely\n",
      "missed node 21_34 division completely\n",
      "missed node 26_25 division completely\n",
      "missed node 4_26 division completely\n",
      "missed node 5_53 division completely\n",
      "missed node 8_42 division completely\n",
      "missed node 9_38 division completely\n",
      "missed node 12_31 division completely\n",
      "missed node 14_35 division completely\n",
      "missed node 16_30 division completely\n",
      "missed node 18_16 division completely\n",
      "missed node 21_36 division completely\n",
      "missed node 22_24 division completely\n",
      "missed node 26_43 division completely\n",
      "missed node 36_55 division completely\n",
      "missed node 45_50 division completely\n",
      "missed node 47_32 division completely\n",
      "missed node 68_23 division completely\n",
      "missed node 71_18 division completely\n",
      "missed node 72_54 division completely\n",
      "missed node 74_29 division completely\n",
      "missed node 79_28 division completely\n",
      "80_25 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "86_26 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 89_36 division completely\n",
      "missed node 91_51 division completely\n",
      "missed node 96_17 division completely\n",
      "105_27 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 106_37 division completely\n",
      "109_40 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 119_22 division completely\n",
      "missed node 122_36 division completely\n",
      "missed node 123_38 division completely\n",
      "missed node 10_13 division completely\n",
      "missed node 11_68 division completely\n",
      "missed node 23_66 division completely\n",
      "missed node 27_14 division completely\n",
      "missed node 48_6 division completely\n",
      "missed node 49_41 division completely\n",
      "missed node 50_40 division completely\n",
      "missed node 57_10 division completely\n",
      "missed node 58_36 division completely\n",
      "missed node 60_0 division completely\n"
     ]
    }
   ],
   "source": [
    "benchmarks = []\n",
    "\n",
    "for results_dir, s in zip([export_gt_dir, export_dc_dir], ['GT', 'Deepcell']):\n",
    "    for data_id in data_ids:\n",
    "        gt_dir = os.path.join(data_dir, f'{data_id}')\n",
    "        res_dir = os.path.join(results_dir, f'{data_id}_RES')\n",
    "\n",
    "        m = TrackingMetrics.from_isbi_dirs(gt_dir, res_dir)\n",
    "        benchmarks.append({\n",
    "            'model': f'Baxter - {s}',\n",
    "            'data_id': data_id,\n",
    "            **m.stats\n",
    "        })\n",
    "        \n",
    "df = pd.DataFrame(benchmarks)\n",
    "df.to_csv('benchmarks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9a720197f97f3642c161e393a7de41873f9dd6c23052d277f498c18bb84bfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
