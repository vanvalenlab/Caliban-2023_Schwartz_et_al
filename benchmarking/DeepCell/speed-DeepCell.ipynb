{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Please select the kernel <code>Python [conda env: deepcell]</code> for this notebook. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepcell.applications import NuclearSegmentation\n",
    "from deepcell_tracking.trk_io import load_trks, save_trk\n",
    "from deepcell_tracking.tracking import CellTracker as _CellTracker\n",
    "\n",
    "sys.path.append('/publication-tracking/benchmarking')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add timers to CellTracker\n",
    "class CellTracker(_CellTracker):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # Add timers\n",
    "        self.timer_ne = 0\n",
    "        self.timer_inf = 0\n",
    "        self.timer_lap = 0\n",
    "\n",
    "    def _get_neighborhood_embeddings(self, **kwargs):\n",
    "        tic = timeit.default_timer()\n",
    "        embeddings = super()._get_neighborhood_embeddings(**kwargs)\n",
    "        toc = timeit.default_timer()\n",
    "\n",
    "        self.timer_ne += toc - tic\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def _track_frame(self, frame):\n",
    "        tic = timeit.default_timer()\n",
    "        cost_matrix, predictions = self._get_cost_matrix(frame)\n",
    "        toc = timeit.default_timer()\n",
    "\n",
    "        self.timer_inf += toc - tic\n",
    "\n",
    "        tic = timeit.default_timer()\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        assignments = np.stack([row_ind, col_ind], axis=1)\n",
    "        self._update_tracks(assignments, frame, predictions)\n",
    "        toc = timeit.default_timer()\n",
    "\n",
    "        self.timer_lap += toc - tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = '/publication-tracking/data/test.trks'\n",
    "\n",
    "data_dir = '/publication-tracking/benchmarking/DeepCell/data'\n",
    "gt_seg_dir = os.path.join(data_dir, 'SEG_GT')\n",
    "pred_seg_dir = os.path.join(data_dir, 'SEG_PRED')\n",
    "\n",
    "for d in [data_dir, gt_seg_dir, pred_seg_dir]:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "        \n",
    "model_urls = {\n",
    "    'NuclearSegmentation': 'https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearSegmentation-75.tar.gz',\n",
    "    'NuclearTrackingNE': 'https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingNE-75.tar.gz',\n",
    "    'NuclearTrackingInf': 'https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingInf-75.tar.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data = load_trks(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearSegmentation-75.tar.gz\n",
      "450633728/450633493 [==============================] - 37s 0us/step\n",
      "450641920/450633493 [==============================] - 37s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 23:20:21.717644: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 23:20:23.396179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10396 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingNE-75.tar.gz\n",
      "786432/781312 [==============================] - 0s 0us/step\n",
      "794624/781312 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingInf-75.tar.gz\n",
      "540672/538726 [==============================] - 0s 0us/step\n",
      "548864/538726 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Download and load each model\n",
    "models = {}\n",
    "for m, url in model_urls.items():\n",
    "    archive_path = tf.keras.utils.get_file(f'{m}.tgz', url, extract=True, cache_subdir='models')\n",
    "    model_path = os.path.splitext(archive_path)[0]\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    models[m] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load segmentation and tracking applications\n",
    "app_seg = NuclearSegmentation(models['NuclearSegmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 23:21:48.627508: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deepcell_toolbox/deep_watershed.py:179: FutureWarning: `selem` is a deprecated argument name for `h_maxima`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  markers = h_maxima(image=maxima,\n"
     ]
    }
   ],
   "source": [
    "for batch_no in range(len(data['lineages'])):\n",
    "    print(batch_no)\n",
    "    tm = {}\n",
    "    \n",
    "    # Pull out relevant data for this batch\n",
    "    X = data['X'][batch_no]\n",
    "    y = data['y'][batch_no]\n",
    "    lineage = data['lineages'][batch_no]\n",
    "    \n",
    "    # Correct discontiguous tracks, which are not allowed by CTC\n",
    "    y, lineage = utils.convert_to_contiguous(y, lineage)\n",
    "\n",
    "    # Determine position of zero padding for removal\n",
    "    slc = utils.find_zero_padding(X)\n",
    "    X = X[slc]\n",
    "    y = y[slc]\n",
    "\n",
    "    # Determine which frames are zero padding\n",
    "    frames = np.sum(y, axis=(1,2)) # True if image not blank\n",
    "    good_frames = np.where(frames)[0]\n",
    "    X = X[:len(good_frames)]\n",
    "    y = y[:len(good_frames)]\n",
    "    \n",
    "    # Generate tracks on predicted segmentations\n",
    "    tic = timeit.default_timer()\n",
    "    y_pred = app_seg.predict(X)\n",
    "    tm['seg'] = timeit.default_timer() - tic\n",
    "\n",
    "    tracker = CellTracking(\n",
    "        X,\n",
    "        y_pred,\n",
    "        models['NuclearTrackingInf'],\n",
    "        neighborhood_encoder=models['NuclearTrackingNE'],\n",
    "        track_length=8\n",
    "    )\n",
    "    tracker.track_cells()\n",
    "    tm['ne'] = tracker.timer_ne\n",
    "    tm['inf'] = tracker.timer_inf\n",
    "    tm['lap'] = tracker.timer_lap\n",
    "\n",
    "    tm['nframes'] = X.shape[0]\n",
    "    tm['nobjects'] = ...\n",
    "\n",
    "    timers.append(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from deepcell_tracking.metrics import TrackingMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/publication-tracking/benchmarking/DeepCell/data'\n",
    "gt_seg_dir = os.path.join(data_dir, 'SEG_GT')\n",
    "pred_seg_dir = os.path.join(data_dir, 'SEG_PRED')\n",
    "\n",
    "pattern = re.compile('\\d{3}_GT')\n",
    "data_ids = [f.split('_')[0] for f in os.listdir(gt_seg_dir) if pattern.fullmatch(f)]\n",
    "\n",
    "node_match_threshold = 0.6\n",
    "\n",
    "ctc_software = '/publication-tracking/benchmarking/CTC_Evaluation_Software'\n",
    "operating_system = 'Linux' # or 'Mac' or 'Win'\n",
    "num_digits = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missed node 1_29 division completely\n",
      "missed node 29_29 division completely\n",
      "missed node 57_10 division completely\n",
      "missed node 60_0 division completely\n",
      "18_16 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 5_6 division completely\n",
      "missed node 121_42 division completely\n",
      "missed node 144_28 division completely\n",
      "missed node 26_25 division completely\n",
      "missed node 1_29 division completely\n",
      "missed node 3_23 division completely\n",
      "29_29 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "corrected division 3_23 as a frameshift division not an error\n",
      "missed node 10_19 division completely\n",
      "15_17 out degree = 1, daughters mismatch.\n",
      "missed node 19_20 division completely\n",
      "29_17 out degree = 1, daughters mismatch.\n",
      "missed node 60_34 division completely\n",
      "missed node 76_7 division completely\n",
      "corrected division 10_19 as a frameshift division not an error\n",
      "corrected division 60_34 as a frameshift division not an error\n",
      "corrected division 76_7 as a frameshift division not an error\n",
      "missed node 23_66 division completely\n",
      "missed node 48_6 division completely\n",
      "missed node 49_41 division completely\n",
      "57_10 out degree = 2, daughters mismatch.\n",
      "missed node 60_0 division completely\n",
      "corrected division 23_66 as a frameshift division not an error\n",
      "corrected division 48_6 as a frameshift division not an error\n",
      "corrected division 49_41 as a frameshift division not an error\n",
      "missed node 5_53 division completely\n",
      "missed node 18_16 division completely\n",
      "missed node 22_24 division completely\n",
      "26_43 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "30_28 out degree = 1, daughters mismatch.\n",
      "missed node 38_31 division completely\n",
      "42_38 out degree = 1, daughters mismatch.\n",
      "missed node 47_32 division completely\n",
      "missed node 68_23 division completely\n",
      "missed node 71_18 division completely\n",
      "missed node 72_54 division completely\n",
      "74_29 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 91_51 division completely\n",
      "missed node 101_18 division completely\n",
      "missed node 119_22 division completely\n",
      "missed node 123_38 division completely\n",
      "corrected division 72_54 as a frameshift division not an error\n",
      "corrected division 47_32 as a frameshift division not an error\n",
      "corrected division 71_18 as a frameshift division not an error\n",
      "corrected division 119_22 as a frameshift division not an error\n",
      "corrected division 22_24 as a frameshift division not an error\n",
      "corrected division 91_51 as a frameshift division not an error\n",
      "corrected division 5_53 as a frameshift division not an error\n",
      "corrected division 68_23 as a frameshift division not an error\n",
      "missed node 14_10 division completely\n",
      "missed node 37_35 division completely\n",
      "missed node 41_26 division completely\n",
      "missed node 50_42 division completely\n",
      "missed node 54_28 division completely\n",
      "missed node 73_5 division completely\n",
      "corrected division 50_42 as a frameshift division not an error\n",
      "corrected division 54_28 as a frameshift division not an error\n",
      "corrected division 73_5 as a frameshift division not an error\n",
      "missed node 5_6 division completely\n",
      "16_9 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "30_37 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 104_34 division completely\n",
      "missed node 121_42 division completely\n",
      "missed node 126_61 division completely\n",
      "127_51 out degree = 1, daughters mismatch.\n",
      "missed node 144_28 division completely\n",
      "missed node 163_66 division completely\n",
      "corrected division 163_66 as a frameshift division not an error\n",
      "missed node 26_25 division completely\n"
     ]
    }
   ],
   "source": [
    "benchmarks = []\n",
    "\n",
    "for results_dir, s in zip([gt_seg_dir, pred_seg_dir], ['GT', 'Deepcell']):\n",
    "    for data_id in data_ids:\n",
    "        results = {\n",
    "            'model': f'Deepcell - {s}',\n",
    "            'data_id': os.path.splitext(data_id)[0]\n",
    "        }\n",
    "        gt_dir = os.path.join(results_dir, f'{data_id}_GT/TRA')\n",
    "        res_dir = os.path.join(results_dir, f'{data_id}_RES')\n",
    "        \n",
    "        # Deepcell benchmarking\n",
    "        m = TrackingMetrics.from_isbi_dirs(gt_dir, res_dir, threshold=node_match_threshold)\n",
    "        results.update(m.stats)\n",
    "        \n",
    "        # CTC metrics\n",
    "        for metric, path in [('DET', 'DETMeasure'), ('SEG', 'SEGMeasure'), ('TRA', 'TRAMeasure')]:\n",
    "            p = subprocess.run([os.path.join(ctc_software, operating_system, path), results_dir, data_id, num_digits],\n",
    "                               stdout=subprocess.PIPE)\n",
    "            outstring = p.stdout\n",
    "            \n",
    "            try:\n",
    "                val = float(outstring.decode('utf-8').split()[-1])\n",
    "                results[metric] = val\n",
    "            except:\n",
    "                print('Benchmarking failure', path, results_dir, data_id)\n",
    "                print(outstring.decode('utf-8'))\n",
    "        \n",
    "        benchmarks.append(results)\n",
    "\n",
    "df = pd.DataFrame(benchmarks)\n",
    "df.to_csv('benchmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
