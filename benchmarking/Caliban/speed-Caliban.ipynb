{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>NOTE</b> Please select the kernel <code>Python [conda env: deepcell]</code> for this notebook. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepcell.applications import NuclearSegmentation\n",
    "from deepcell_tracking.trk_io import load_trks, save_trk\n",
    "from deepcell_tracking.tracking import CellTracker as _CellTracker\n",
    "from deepcell_tracking.tracking import linear_sum_assignment\n",
    "\n",
    "sys.path.append('/notebooks/benchmarking')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add timers to CellTracker\n",
    "class CellTracker(_CellTracker):\n",
    "\n",
    "    def __init__(self, X, y, model, neighborhood_encoder, track_length):\n",
    "        # Add timers\n",
    "        self.timer_ne = 0\n",
    "        self.timer_inf = 0\n",
    "        self.timer_lap = 0\n",
    "        \n",
    "        super().__init__(X, y, model, neighborhood_encoder=neighborhood_encoder, track_length=track_length)\n",
    "\n",
    "    def _get_neighborhood_embeddings(self, **kwargs):\n",
    "        tic = timeit.default_timer()\n",
    "        embeddings = super()._get_neighborhood_embeddings(**kwargs)\n",
    "        toc = timeit.default_timer()\n",
    "\n",
    "        self.timer_ne += toc - tic\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def _track_frame(self, frame):\n",
    "        tic = timeit.default_timer()\n",
    "        cost_matrix, predictions = self._get_cost_matrix(frame)\n",
    "        toc = timeit.default_timer()\n",
    "\n",
    "        self.timer_inf += toc - tic\n",
    "\n",
    "        tic = timeit.default_timer()\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        assignments = np.stack([row_ind, col_ind], axis=1)\n",
    "        self._update_tracks(assignments, frame, predictions)\n",
    "        toc = timeit.default_timer()\n",
    "\n",
    "        self.timer_lap += toc - tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = '/notebooks/data/tracking/test.trks'\n",
    "        \n",
    "model_urls = {\n",
    "    'NuclearSegmentation': 'https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearSegmentation-75.tar.gz',\n",
    "    'NuclearTrackingNE': 'https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingNE-75.tar.gz',\n",
    "    'NuclearTrackingInf': 'https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingInf-75.tar.gz'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data = load_trks(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearSegmentation-75.tar.gz\n",
      "450633728/450633493 [==============================] - 9s 0us/step\n",
      "450641920/450633493 [==============================] - 9s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 21:27:03.378048: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 21:27:03.790551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46711 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingNE-75.tar.gz\n",
      "786432/781312 [==============================] - 0s 0us/step\n",
      "794624/781312 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingInf-75.tar.gz\n",
      "540672/538726 [==============================] - 0s 0us/step\n",
      "548864/538726 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Download and load each model\n",
    "models = {}\n",
    "for m, url in model_urls.items():\n",
    "    archive_path = tf.keras.utils.get_file(f'{m}.tgz', url, extract=True, cache_subdir='models')\n",
    "    model_path = os.path.splitext(archive_path)[0]\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    models[m] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load segmentation and tracking applications\n",
    "app_seg = NuclearSegmentation(models['NuclearSegmentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 21:27:47.178165: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2023-06-02 21:28:18.571852: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 99 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eef9856fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 99 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eef9856fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 101 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eef9856fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 101 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eef9856fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "timers = []\n",
    "for it in range(3):\n",
    "    for batch_no in range(len(data['lineages'])):\n",
    "        print(batch_no)\n",
    "        tm = {'batch': batch_no, 'iteration': it}\n",
    "\n",
    "        # Pull out relevant data for this batch\n",
    "        X = data['X'][batch_no]\n",
    "        y = data['y'][batch_no]\n",
    "        lineage = data['lineages'][batch_no]\n",
    "\n",
    "        # Correct discontiguous tracks, which are not allowed by CTC\n",
    "        y, lineage = utils.convert_to_contiguous(y, lineage)\n",
    "\n",
    "        # Determine position of zero padding for removal\n",
    "        slc = utils.find_zero_padding(X)\n",
    "        X = X[slc]\n",
    "        y = y[slc]\n",
    "\n",
    "        # Determine which frames are zero padding\n",
    "        frames = np.sum(y, axis=(1,2)) # True if image not blank\n",
    "        good_frames = np.where(frames)[0]\n",
    "        X = X[:len(good_frames)]\n",
    "        y = y[:len(good_frames)]\n",
    "\n",
    "        # Generate tracks on predicted segmentations\n",
    "        tic = timeit.default_timer()\n",
    "        y_pred = app_seg.predict(X)\n",
    "        tm['seg'] = timeit.default_timer() - tic\n",
    "\n",
    "        tracker = CellTracker(\n",
    "            X,\n",
    "            y_pred,\n",
    "            models['NuclearTrackingInf'],\n",
    "            neighborhood_encoder=models['NuclearTrackingNE'],\n",
    "            track_length=8\n",
    "        )\n",
    "        tracker.track_cells()\n",
    "        tm['ne'] = tracker.timer_ne\n",
    "        tm['inf'] = tracker.timer_inf\n",
    "        tm['lap'] = tracker.timer_lap\n",
    "\n",
    "        tm['nframes'] = X.shape[0]\n",
    "        tm['nobjects'] = sum([len(np.unique(y[t])) - 1 for t in range(y.shape[0])])\n",
    "\n",
    "        timers.append(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(timers)\n",
    "df.to_csv('speed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
