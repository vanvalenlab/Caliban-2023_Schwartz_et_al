{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "Resave data as a set of tiff files in order to match Cell Tracking Challenge conventions which are expected by EmbedTrack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tifffile import imwrite\n",
    "\n",
    "from deepcell_tracking.isbi_utils import trk_to_isbi\n",
    "from deepcell_tracking.trk_io import load_trks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = '/data/test.trks'\n",
    "data_dir = '/EmbedTrack/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test split of the tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_trks(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zero_padding(X):\n",
    "    \"\"\"Remove zero padding to avoid adverse effects on model performance\"\"\"\n",
    "    # Calculate position of padding based on first frame\n",
    "    # Assume that padding is in blocks on the edges of image\n",
    "    good_rows = np.where(X[0].any(axis=0))[0]\n",
    "    good_cols = np.where(X[0].any(axis=1))[0]\n",
    "\n",
    "    slc = (\n",
    "        slice(None),\n",
    "        slice(good_cols[0], good_cols[-1] + 1),\n",
    "        slice(good_rows[0], good_rows[-1] + 1),\n",
    "        slice(None)\n",
    "    )\n",
    "\n",
    "    return slc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each batch of the test split to the standard ISBI format which is compatible with most of the models that we will tst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_no in range(len(data['lineages'])):\n",
    "    # Build subdirectories for data\n",
    "    raw_dir = os.path.join(data_dir, '{:03}'.format(batch_no + 1))\n",
    "    gt_dir = os.path.join(data_dir, '{:03}_GT'.format(batch_no + 1))\n",
    "    seg_dir = os.path.join(gt_dir, 'SEG')\n",
    "    tra_dir = os.path.join(gt_dir, 'TRA')\n",
    "    \n",
    "    # Create directories if needed\n",
    "    for d in (raw_dir, gt_dir, seg_dir, tra_dir):\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "                \n",
    "    # Pull out relevant data for this batch\n",
    "    X = data['X'][batch_no]\n",
    "    y = data['y'][batch_no]\n",
    "    lineages = data['lineages'][batch_no]\n",
    "    \n",
    "    # Determine position of zero padding for removal\n",
    "    slc = find_zero_padding(X)\n",
    "    X = X[slc]\n",
    "    y = y[slc]\n",
    "    \n",
    "    # Need to translate lineages and adjust images to match restrictive ISBI format\n",
    "    # Prepare output txt\n",
    "    text_file = os.path.join(tra_dir, 'man_track.txt')\n",
    "    df = trk_to_isbi(lineages)\n",
    "    df.to_csv(text_file, sep=' ', header=False)\n",
    "    \n",
    "    # Determine which frames are zero padding\n",
    "    frames = np.sum(y, axis=(1,2)) # True if image not blank\n",
    "    good_frames = np.where(frames)[0]\n",
    "    # We assume here that the empty frames are at the end of the movie (padding rather than skipped)\n",
    "    movie_len = len(good_frames)\n",
    "    \n",
    "    # Save each frame of the movie as an individual tif\n",
    "    channel = 0 # These images should only have one channel\n",
    "    for i in range(movie_len):\n",
    "        name_raw = os.path.join(raw_dir, 't{:03}.tif'.format(i))\n",
    "        name_tracked_seg = os.path.join(seg_dir, 'man_seg{:03}.tif'.format(i))\n",
    "        name_tracked_tra = os.path.join(tra_dir, 'man_track{:03}.tif'.format(i))\n",
    "        \n",
    "        imwrite(name_raw, X[i, ..., channel])\n",
    "        imwrite(name_tracked_seg, y[i, ..., channel].astype('uint16'))\n",
    "        imwrite(name_tracked_tra, y[i, ..., channel].astype('uint16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EmbedTrack Inference\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> This notebook must be moved into the `embedtrack` folder in order to correctly import `embedtrack` modules.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model_dir = '/EmbedTrack/KIT-Loe-GE/models'\n",
    "models = [\n",
    "    'Fluo-N2DL-HeLa',\n",
    "    'Fluo-N2DH-SIM+',\n",
    "    'Fluo-N2DH-GOWT1'\n",
    "]\n",
    "\n",
    "data_dir = '/EmbedTrack/data'\n",
    "\n",
    "pattern = re.compile('\\d{3}')\n",
    "data_ids = [f for f in os.listdir(data_dir) if pattern.fullmatch(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/venv_embedtrack/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal.windows import gaussian\n",
    "import tifffile\n",
    "import torch\n",
    "\n",
    "from embedtrack.infer.inference import (\n",
    "    extend_grid,\n",
    "    infer_sequence,\n",
    "    create_inference_dict,\n",
    "    calc_padded_img_size,\n",
    "    init_model,\n",
    "    foi_correction,\n",
    "    rename_to_ctc_format,\n",
    "    device,\n",
    ")\n",
    "from embedtrack.infer.infer_ctc_data import fill_empty_frames\n",
    "from embedtrack.utils.clustering import Cluster\n",
    "from embedtrack.utils.create_dicts import create_model_dict\n",
    "from embedtrack.utils.utils import get_img_files\n",
    "\n",
    "\n",
    "# This is a modified versioon of embedtrack.infer.infer_ctc_data.inference\n",
    "# which eliminates the requirement that the data name matches the model name\n",
    "\n",
    "def inference(raw_data_path, model_path, config_file, batch_size=32):\n",
    "    \"\"\"\n",
    "    Segment and track a ctc dataset using a trained EmbedTrack model.\n",
    "    Args:\n",
    "        raw_data_path: string\n",
    "            Path to the raw images\n",
    "        model_path: string\n",
    "            Path to the weights of the trained model\n",
    "        config_file: string\n",
    "            Path to the configuration of the model\n",
    "        batch_size: int\n",
    "            batch size during inference\n",
    "    \"\"\"\n",
    "    raw_data_path = Path(raw_data_path)\n",
    "    model_path = Path(model_path)\n",
    "\n",
    "    data_id = raw_data_path.parts[-1]\n",
    "    data_set = raw_data_path.parts[-2]\n",
    "\n",
    "    ctc_res_path = raw_data_path.parent / (data_id + \"_RES\")\n",
    "    temp_res_path = \"./temp\"\n",
    "    if not os.path.exists(temp_res_path):\n",
    "        os.makedirs(temp_res_path)\n",
    "    else:\n",
    "        shutil.rmtree(temp_res_path)\n",
    "\n",
    "    # These lines are the modification\n",
    "    # if data_set not in model_path.as_posix():\n",
    "    #     raise Warning(f\"The model {model_path} is not named as the data set {data_set}\")\n",
    "\n",
    "    overlap = 0.25\n",
    "\n",
    "    with open(config_file) as file:\n",
    "        train_config = json.load(file)\n",
    "\n",
    "    model_class = train_config[\"model_dict\"][\"name\"]\n",
    "    crop_size = train_config[\"train_dict\"][\"crop_size\"]\n",
    "\n",
    "    image_size = tifffile.imread(\n",
    "        os.path.join(raw_data_path, os.listdir(raw_data_path)[0])\n",
    "    ).shape\n",
    "\n",
    "    project_config = dict(\n",
    "        image_dir=raw_data_path,\n",
    "        res_dir=temp_res_path,\n",
    "        model_cktp_path=model_path,\n",
    "        model_class=model_class,\n",
    "        grid_y=train_config[\"grid_dict\"][\"grid_y\"],\n",
    "        grid_x=train_config[\"grid_dict\"][\"grid_x\"],\n",
    "        pixel_y=train_config[\"grid_dict\"][\"pixel_y\"],\n",
    "        pixel_x=train_config[\"grid_dict\"][\"pixel_x\"],\n",
    "        overlap=overlap,\n",
    "        crop_size=crop_size,  # multiple of 2\n",
    "        img_size=image_size,\n",
    "        padded_img_size=None,\n",
    "    )\n",
    "    project_config[\"padded_img_size\"] = calc_padded_img_size(\n",
    "        project_config[\"img_size\"],\n",
    "        project_config[\"crop_size\"],\n",
    "        project_config[\"overlap\"],\n",
    "    )[0]\n",
    "    window_function_1d = gaussian(\n",
    "        project_config[\"crop_size\"], project_config[\"crop_size\"] // 4\n",
    "    )\n",
    "    project_config[\"window_func\"] = window_function_1d.reshape(\n",
    "        -1, 1\n",
    "    ) * window_function_1d.reshape(1, -1)\n",
    "\n",
    "    dataset_dict = create_inference_dict(\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # init model\n",
    "    input_channels = train_config[\"model_dict\"][\"kwargs\"][\"input_channels\"]\n",
    "    n_classes = train_config[\"model_dict\"][\"kwargs\"][\"n_classes\"]\n",
    "    model_dict = create_model_dict(\n",
    "        input_channels=input_channels,\n",
    "        n_classes=n_classes,\n",
    "    )\n",
    "    model = init_model(model_dict, project_config)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # clustering\n",
    "    cluster = Cluster(\n",
    "        project_config[\"grid_y\"],\n",
    "        project_config[\"grid_x\"],\n",
    "        project_config[\"pixel_y\"],\n",
    "        project_config[\"pixel_x\"],\n",
    "    )\n",
    "    cluster = extend_grid(cluster, image_size)\n",
    "    tracking_dir = os.path.join(project_config[\"res_dir\"], \"tracking\")\n",
    "    infer_sequence(\n",
    "        model,\n",
    "        dataset_dict,\n",
    "        model_dict,\n",
    "        project_config,\n",
    "        cluster,\n",
    "        min_mask_size=train_config[\"train_dict\"][\"min_mask_size\"] * 0.5,\n",
    "    )\n",
    "    foi_correction(tracking_dir, data_set)\n",
    "    fill_empty_frames(tracking_dir)\n",
    "    lineage = pd.read_csv(\n",
    "        os.path.join(tracking_dir, \"res_track.txt\"), sep=\" \", header=None\n",
    "    )\n",
    "    max_id = lineage[0].index.max()\n",
    "    if max_id >= 2 ** 16 - 1:\n",
    "        raise AssertionError(\n",
    "            \"Max Track id > 2**16 - uint16 transformation needed for ctc\"\n",
    "            \" measure will lead to buffer overflow!\"\n",
    "        )\n",
    "    rename_to_ctc_format(tracking_dir, ctc_res_path)\n",
    "    shutil.rmtree(temp_res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Fluo-N2DL-HeLa ------\n",
      "Skipping 011, already complete\n",
      "Skipping 002, already complete\n",
      "Skipping 009, already complete\n",
      "Skipping 003, already complete\n",
      "Skipping 012, already complete\n",
      "Skipping 007, already complete\n",
      "Skipping 001, already complete\n",
      "Skipping 006, already complete\n",
      "Skipping 010, already complete\n",
      "Skipping 004, already complete\n",
      "Skipping 008, already complete\n",
      "Skipping 005, already complete\n",
      "------ Fluo-N2DH-SIM+ ------\n",
      "Skipping 011, already complete\n",
      "Skipping 002, already complete\n",
      "Skipping 009, already complete\n",
      "Skipping 003, already complete\n",
      "Skipping 012, already complete\n",
      "Skipping 007, already complete\n",
      "Skipping 001, already complete\n",
      "Skipping 006, already complete\n",
      "Skipping 010, already complete\n",
      "Skipping 004, already complete\n",
      "Skipping 008, already complete\n",
      "Skipping 005, already complete\n",
      "------ Fluo-N2DH-GOWT1 ------\n",
      "Skipping 011, already complete\n",
      "Skipping 002, already complete\n",
      "Skipping 009, already complete\n",
      "Skipping 003, already complete\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t054.tif\n",
      "Issue with /EmbedTrack/data/012\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t049.tif\n",
      "Save tracking mask t048.tif\n",
      "Save tracking mask t047.tif\n",
      "Save tracking mask t046.tif\n",
      "Save tracking mask t045.tif\n",
      "Save tracking mask t044.tif\n",
      "Save tracking mask t043.tif\n",
      "Save tracking mask t042.tif\n",
      "Save tracking mask t041.tif\n",
      "Save tracking mask t040.tif\n",
      "Save tracking mask t039.tif\n",
      "Save tracking mask t038.tif\n",
      "Save tracking mask t037.tif\n",
      "Save tracking mask t036.tif\n",
      "Save tracking mask t035.tif\n",
      "Save tracking mask t034.tif\n",
      "Save tracking mask t033.tif\n",
      "Save tracking mask t032.tif\n",
      "Save tracking mask t031.tif\n",
      "Save tracking mask t030.tif\n",
      "Save tracking mask t029.tif\n",
      "Save tracking mask t028.tif\n",
      "Save tracking mask t027.tif\n",
      "Save tracking mask t026.tif\n",
      "Save tracking mask t025.tif\n",
      "Save tracking mask t024.tif\n",
      "Save tracking mask t023.tif\n",
      "Save tracking mask t022.tif\n",
      "Save tracking mask t021.tif\n",
      "Save tracking mask t020.tif\n",
      "Save tracking mask t019.tif\n",
      "Save tracking mask t018.tif\n",
      "Save tracking mask t017.tif\n",
      "Save tracking mask t016.tif\n",
      "Save tracking mask t015.tif\n",
      "Save tracking mask t014.tif\n",
      "Save tracking mask t013.tif\n",
      "Save tracking mask t012.tif\n",
      "Save tracking mask t011.tif\n",
      "Save tracking mask t010.tif\n",
      "Save tracking mask t009.tif\n",
      "Save tracking mask t008.tif\n",
      "Save tracking mask t007.tif\n",
      "Save tracking mask t006.tif\n",
      "Save tracking mask t005.tif\n",
      "Save tracking mask t004.tif\n",
      "Save tracking mask t003.tif\n",
      "Save tracking mask t002.tif\n",
      "Save tracking mask t001.tif\n",
      "Save tracking mask t000.tif\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t041.tif\n",
      "Save tracking mask t040.tif\n",
      "Save tracking mask t039.tif\n",
      "Save tracking mask t038.tif\n",
      "Save tracking mask t037.tif\n",
      "Save tracking mask t036.tif\n",
      "Save tracking mask t035.tif\n",
      "Save tracking mask t034.tif\n",
      "Save tracking mask t033.tif\n",
      "Save tracking mask t032.tif\n",
      "Save tracking mask t031.tif\n",
      "Save tracking mask t030.tif\n",
      "Save tracking mask t029.tif\n",
      "Save tracking mask t028.tif\n",
      "Save tracking mask t027.tif\n",
      "Save tracking mask t026.tif\n",
      "Save tracking mask t025.tif\n",
      "Save tracking mask t024.tif\n",
      "Save tracking mask t023.tif\n",
      "Save tracking mask t022.tif\n",
      "Save tracking mask t021.tif\n",
      "Save tracking mask t020.tif\n",
      "Save tracking mask t019.tif\n",
      "Save tracking mask t018.tif\n",
      "Save tracking mask t017.tif\n",
      "Save tracking mask t016.tif\n",
      "Save tracking mask t015.tif\n",
      "Save tracking mask t014.tif\n",
      "Save tracking mask t013.tif\n",
      "Save tracking mask t012.tif\n",
      "Save tracking mask t011.tif\n",
      "Save tracking mask t010.tif\n",
      "Save tracking mask t009.tif\n",
      "Save tracking mask t008.tif\n",
      "Save tracking mask t007.tif\n",
      "Save tracking mask t006.tif\n",
      "Save tracking mask t005.tif\n",
      "Save tracking mask t004.tif\n",
      "Save tracking mask t003.tif\n",
      "Save tracking mask t002.tif\n",
      "Save tracking mask t001.tif\n",
      "Save tracking mask t000.tif\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t049.tif\n",
      "Save tracking mask t048.tif\n",
      "Save tracking mask t047.tif\n",
      "Save tracking mask t046.tif\n",
      "Save tracking mask t045.tif\n",
      "Save tracking mask t044.tif\n",
      "Save tracking mask t043.tif\n",
      "Save tracking mask t042.tif\n",
      "Save tracking mask t041.tif\n",
      "Save tracking mask t040.tif\n",
      "Save tracking mask t039.tif\n",
      "Save tracking mask t038.tif\n",
      "Save tracking mask t037.tif\n",
      "Save tracking mask t036.tif\n",
      "Save tracking mask t035.tif\n",
      "Save tracking mask t034.tif\n",
      "Save tracking mask t033.tif\n",
      "Save tracking mask t032.tif\n",
      "Save tracking mask t031.tif\n",
      "Save tracking mask t030.tif\n",
      "Save tracking mask t029.tif\n",
      "Save tracking mask t028.tif\n",
      "Save tracking mask t027.tif\n",
      "Save tracking mask t026.tif\n",
      "Save tracking mask t025.tif\n",
      "Save tracking mask t024.tif\n",
      "Save tracking mask t023.tif\n",
      "Save tracking mask t022.tif\n",
      "Save tracking mask t021.tif\n",
      "Save tracking mask t020.tif\n",
      "Save tracking mask t019.tif\n",
      "Save tracking mask t018.tif\n",
      "Save tracking mask t017.tif\n",
      "Save tracking mask t016.tif\n",
      "Save tracking mask t015.tif\n",
      "Save tracking mask t014.tif\n",
      "Save tracking mask t013.tif\n",
      "Save tracking mask t012.tif\n",
      "Save tracking mask t011.tif\n",
      "Save tracking mask t010.tif\n",
      "Save tracking mask t009.tif\n",
      "Save tracking mask t008.tif\n",
      "Save tracking mask t007.tif\n",
      "Save tracking mask t006.tif\n",
      "Save tracking mask t005.tif\n",
      "Save tracking mask t004.tif\n",
      "Save tracking mask t003.tif\n",
      "Save tracking mask t002.tif\n",
      "Save tracking mask t001.tif\n",
      "Save tracking mask t000.tif\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t064.tif\n",
      "Issue with /EmbedTrack/data/010\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t041.tif\n",
      "Save tracking mask t040.tif\n",
      "Save tracking mask t039.tif\n",
      "Save tracking mask t038.tif\n",
      "Save tracking mask t037.tif\n",
      "Save tracking mask t036.tif\n",
      "Save tracking mask t035.tif\n",
      "Save tracking mask t034.tif\n",
      "Save tracking mask t033.tif\n",
      "Save tracking mask t032.tif\n",
      "Save tracking mask t031.tif\n",
      "Save tracking mask t030.tif\n",
      "Save tracking mask t029.tif\n",
      "Save tracking mask t028.tif\n",
      "Save tracking mask t027.tif\n",
      "Save tracking mask t026.tif\n",
      "Save tracking mask t025.tif\n",
      "Save tracking mask t024.tif\n",
      "Save tracking mask t023.tif\n",
      "Save tracking mask t022.tif\n",
      "Save tracking mask t021.tif\n",
      "Save tracking mask t020.tif\n",
      "Save tracking mask t019.tif\n",
      "Save tracking mask t018.tif\n",
      "Save tracking mask t017.tif\n",
      "Save tracking mask t016.tif\n",
      "Save tracking mask t015.tif\n",
      "Save tracking mask t014.tif\n",
      "Save tracking mask t013.tif\n",
      "Save tracking mask t012.tif\n",
      "Save tracking mask t011.tif\n",
      "Save tracking mask t010.tif\n",
      "Save tracking mask t009.tif\n",
      "Save tracking mask t008.tif\n",
      "Save tracking mask t007.tif\n",
      "Save tracking mask t006.tif\n",
      "Save tracking mask t005.tif\n",
      "Save tracking mask t004.tif\n",
      "Save tracking mask t003.tif\n",
      "Save tracking mask t002.tif\n",
      "Save tracking mask t001.tif\n",
      "Save tracking mask t000.tif\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t070.tif\n",
      "Save tracking mask t069.tif\n",
      "Save tracking mask t068.tif\n",
      "Save tracking mask t067.tif\n",
      "Save tracking mask t066.tif\n",
      "Save tracking mask t065.tif\n",
      "Save tracking mask t064.tif\n",
      "Save tracking mask t063.tif\n",
      "Save tracking mask t062.tif\n",
      "Save tracking mask t061.tif\n",
      "Save tracking mask t060.tif\n",
      "Save tracking mask t059.tif\n",
      "Save tracking mask t058.tif\n",
      "Save tracking mask t057.tif\n",
      "Save tracking mask t056.tif\n",
      "Save tracking mask t055.tif\n",
      "Save tracking mask t054.tif\n",
      "Save tracking mask t053.tif\n",
      "Save tracking mask t052.tif\n",
      "Save tracking mask t051.tif\n",
      "Save tracking mask t050.tif\n",
      "Save tracking mask t049.tif\n",
      "Save tracking mask t048.tif\n",
      "Save tracking mask t047.tif\n",
      "Save tracking mask t046.tif\n",
      "Save tracking mask t045.tif\n",
      "Save tracking mask t044.tif\n",
      "Save tracking mask t043.tif\n",
      "Save tracking mask t042.tif\n",
      "Save tracking mask t041.tif\n",
      "Save tracking mask t040.tif\n",
      "Save tracking mask t039.tif\n",
      "Save tracking mask t038.tif\n",
      "Save tracking mask t037.tif\n",
      "Save tracking mask t036.tif\n",
      "Save tracking mask t035.tif\n",
      "Save tracking mask t034.tif\n",
      "Save tracking mask t033.tif\n",
      "Save tracking mask t032.tif\n",
      "Save tracking mask t031.tif\n",
      "Save tracking mask t030.tif\n",
      "Save tracking mask t029.tif\n",
      "Save tracking mask t028.tif\n",
      "Save tracking mask t027.tif\n",
      "Save tracking mask t026.tif\n",
      "Save tracking mask t025.tif\n",
      "Save tracking mask t024.tif\n",
      "Save tracking mask t023.tif\n",
      "Save tracking mask t022.tif\n",
      "Save tracking mask t021.tif\n",
      "Save tracking mask t020.tif\n",
      "Save tracking mask t019.tif\n",
      "Save tracking mask t018.tif\n",
      "Save tracking mask t017.tif\n",
      "Save tracking mask t016.tif\n",
      "Save tracking mask t015.tif\n",
      "Save tracking mask t014.tif\n",
      "Save tracking mask t013.tif\n",
      "Save tracking mask t012.tif\n",
      "Save tracking mask t011.tif\n",
      "Save tracking mask t010.tif\n",
      "Save tracking mask t009.tif\n",
      "Save tracking mask t008.tif\n",
      "Save tracking mask t007.tif\n",
      "Save tracking mask t006.tif\n",
      "Save tracking mask t005.tif\n",
      "Save tracking mask t004.tif\n",
      "Save tracking mask t003.tif\n",
      "Save tracking mask t002.tif\n",
      "Save tracking mask t001.tif\n",
      "Save tracking mask t000.tif\n",
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to [4, 1, 2], \n",
      " -- input channels equal to 1, \n",
      " -- name equal to 2d\n",
      "Creating branched erfnet with [4, 1, 2] classes\n",
      "Save tracking mask t041.tif\n",
      "Save tracking mask t040.tif\n",
      "Save tracking mask t039.tif\n",
      "Save tracking mask t038.tif\n",
      "Save tracking mask t037.tif\n",
      "Save tracking mask t036.tif\n",
      "Save tracking mask t035.tif\n",
      "Save tracking mask t034.tif\n",
      "Save tracking mask t033.tif\n",
      "Save tracking mask t032.tif\n",
      "Save tracking mask t031.tif\n",
      "Save tracking mask t030.tif\n",
      "Save tracking mask t029.tif\n",
      "Save tracking mask t028.tif\n",
      "Save tracking mask t027.tif\n",
      "Save tracking mask t026.tif\n",
      "Save tracking mask t025.tif\n",
      "Save tracking mask t024.tif\n",
      "Save tracking mask t023.tif\n",
      "Save tracking mask t022.tif\n",
      "Save tracking mask t021.tif\n",
      "Save tracking mask t020.tif\n",
      "Save tracking mask t019.tif\n",
      "Save tracking mask t018.tif\n",
      "Save tracking mask t017.tif\n",
      "Save tracking mask t016.tif\n",
      "Save tracking mask t015.tif\n",
      "Save tracking mask t014.tif\n",
      "Save tracking mask t013.tif\n",
      "Save tracking mask t012.tif\n",
      "Save tracking mask t011.tif\n",
      "Save tracking mask t010.tif\n",
      "Save tracking mask t009.tif\n",
      "Save tracking mask t008.tif\n",
      "Save tracking mask t007.tif\n",
      "Save tracking mask t006.tif\n",
      "Save tracking mask t005.tif\n",
      "Save tracking mask t004.tif\n",
      "Save tracking mask t003.tif\n",
      "Save tracking mask t002.tif\n",
      "Save tracking mask t001.tif\n",
      "Save tracking mask t000.tif\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print(f'------ {m} ------')\n",
    "    res_subdir = os.path.join(data_dir, 'results', m)\n",
    "    if not os.path.exists(res_subdir):\n",
    "        os.makedirs(res_subdir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, m, 'best_iou_model.pth')\n",
    "    config_file = os.path.join(model_dir, m, 'config.json')\n",
    "\n",
    "    for data_id in data_ids:\n",
    "        data_path = os.path.join(data_dir, data_id)\n",
    "        temp_results_path = os.path.join(data_dir, f'{data_id}_RES')\n",
    "        final_results_path = os.path.join(res_subdir, f'{data_id}_RES')\n",
    "        if os.path.exists(final_results_path):\n",
    "            print(f'Skipping {data_id}, already complete')\n",
    "            continue\n",
    "        try:\n",
    "            inference(data_path, model_path, config_file, batch_size=batch_size)\n",
    "            # Move results into the results subdirectory\n",
    "            shutil.move(temp_results_path, final_results_path)\n",
    "        except TypeError:\n",
    "            print('Issue with', data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tifffile import imread\n",
    "\n",
    "from deepcell_tracking.metrics import TrackingMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'#'/EmbedTrack/data'\n",
    "results_dir = 'data/results'#'/EmbedTrack/data/results'\n",
    "\n",
    "pattern = re.compile('\\d{3}')\n",
    "data_ids = [f for f in os.listdir(data_dir) if pattern.fullmatch(f)]\n",
    "\n",
    "node_match_threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Fluo-N2DH-SIM+ ------\n",
      "missed node 14_10 division completely\n",
      "missed node 17_24 division completely\n",
      "missed node 18_9 division completely\n",
      "missed node 21_42 division completely\n",
      "missed node 25_36 division completely\n",
      "missed node 37_35 division completely\n",
      "missed node 38_5 division completely\n",
      "missed node 41_26 division completely\n",
      "missed node 43_4 division completely\n",
      "missed node 46_35 division completely\n",
      "missed node 49_6 division completely\n",
      "missed node 50_42 division completely\n",
      "missed node 54_28 division completely\n",
      "missed node 57_12 division completely\n",
      "missed node 73_5 division completely\n",
      "missed node 21_19 division completely\n",
      "missed node 5_6 division completely\n",
      "missed node 10_66 division completely\n",
      "missed node 15_66 division completely\n",
      "missed node 16_9 division completely\n",
      "missed node 22_56 division completely\n",
      "missed node 25_57 division completely\n",
      "missed node 26_3 division completely\n",
      "missed node 28_39 division completely\n",
      "missed node 30_37 division completely\n",
      "missed node 35_52 division completely\n",
      "missed node 48_44 division completely\n",
      "missed node 51_28 division completely\n",
      "missed node 54_2 division completely\n",
      "missed node 55_27 division completely\n",
      "missed node 57_49 division completely\n",
      "missed node 62_3 division completely\n",
      "missed node 63_2 division completely\n",
      "missed node 66_12 division completely\n",
      "missed node 67_40 division completely\n",
      "missed node 70_52 division completely\n",
      "missed node 74_47 division completely\n",
      "missed node 76_44 division completely\n",
      "missed node 78_45 division completely\n",
      "missed node 80_61 division completely\n",
      "missed node 86_7 division completely\n",
      "missed node 88_27 division completely\n",
      "missed node 93_10 division completely\n",
      "missed node 94_36 division completely\n",
      "95_52 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 97_60 division completely\n",
      "missed node 103_4 division completely\n",
      "missed node 104_34 division completely\n",
      "missed node 112_6 division completely\n",
      "missed node 115_45 division completely\n",
      "missed node 118_0 division completely\n",
      "missed node 121_42 division completely\n",
      "missed node 124_21 division completely\n",
      "missed node 125_22 division completely\n",
      "missed node 126_61 division completely\n",
      "missed node 127_51 division completely\n",
      "missed node 128_43 division completely\n",
      "missed node 132_23 division completely\n",
      "missed node 133_24 division completely\n",
      "missed node 135_25 division completely\n",
      "missed node 140_10 division completely\n",
      "missed node 141_35 division completely\n",
      "missed node 142_17 division completely\n",
      "missed node 144_28 division completely\n",
      "missed node 147_33 division completely\n",
      "missed node 148_59 division completely\n",
      "missed node 150_40 division completely\n",
      "missed node 152_62 division completely\n",
      "missed node 160_64 division completely\n",
      "missed node 163_66 division completely\n",
      "missed node 167_7 division completely\n",
      "missed node 179_68 division completely\n",
      "missed node 185_49 division completely\n",
      "missed node 1_29 division completely\n",
      "missed node 3_23 division completely\n",
      "missed node 11_22 division completely\n",
      "missed node 17_16 division completely\n",
      "missed node 20_38 division completely\n",
      "missed node 29_29 division completely\n",
      "missed node 38_34 division completely\n",
      "missed node 47_17 division completely\n",
      "missed node 6_17 division completely\n",
      "missed node 8_18 division completely\n",
      "missed node 10_19 division completely\n",
      "missed node 15_17 division completely\n",
      "missed node 17_6 division completely\n",
      "missed node 19_20 division completely\n",
      "missed node 22_5 division completely\n",
      "missed node 29_17 division completely\n",
      "missed node 59_10 division completely\n",
      "missed node 60_34 division completely\n",
      "missed node 76_7 division completely\n",
      "missed node 77_16 division completely\n",
      "missed node 79_9 division completely\n",
      "80_9 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 82_17 division completely\n",
      "missed node 83_18 division completely\n",
      "missed node 1_48 division completely\n",
      "missed node 9_28 division completely\n",
      "missed node 21_34 division completely\n",
      "missed node 26_25 division completely\n",
      "missed node 4_26 division completely\n",
      "missed node 5_53 division completely\n",
      "missed node 8_42 division completely\n",
      "missed node 9_38 division completely\n",
      "missed node 12_31 division completely\n",
      "missed node 13_54 division completely\n",
      "missed node 14_35 division completely\n",
      "missed node 15_46 division completely\n",
      "missed node 16_30 division completely\n",
      "missed node 18_16 division completely\n",
      "missed node 21_36 division completely\n",
      "missed node 22_24 division completely\n",
      "missed node 23_17 division completely\n",
      "missed node 25_37 division completely\n",
      "missed node 26_43 division completely\n",
      "missed node 29_32 division completely\n",
      "missed node 30_28 division completely\n",
      "missed node 35_29 division completely\n",
      "missed node 36_55 division completely\n",
      "missed node 38_31 division completely\n",
      "missed node 39_57 division completely\n",
      "missed node 42_38 division completely\n",
      "missed node 45_50 division completely\n",
      "missed node 47_32 division completely\n",
      "missed node 48_53 division completely\n",
      "missed node 53_28 division completely\n",
      "missed node 63_51 division completely\n",
      "65_47 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "68_23 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 71_18 division completely\n",
      "missed node 72_54 division completely\n",
      "missed node 74_29 division completely\n",
      "missed node 76_34 division completely\n",
      "missed node 79_28 division completely\n",
      "missed node 80_25 division completely\n",
      "missed node 86_26 division completely\n",
      "missed node 89_36 division completely\n",
      "missed node 91_51 division completely\n",
      "missed node 95_50 division completely\n",
      "missed node 96_17 division completely\n",
      "missed node 97_36 division completely\n",
      "missed node 101_18 division completely\n",
      "missed node 103_42 division completely\n",
      "missed node 105_27 division completely\n",
      "missed node 106_37 division completely\n",
      "missed node 107_38 division completely\n",
      "missed node 109_40 division completely\n",
      "missed node 110_19 division completely\n",
      "missed node 113_54 division completely\n",
      "missed node 117_5 division completely\n",
      "missed node 119_22 division completely\n",
      "missed node 121_33 division completely\n",
      "missed node 122_36 division completely\n",
      "missed node 123_38 division completely\n",
      "missed node 2_37 division completely\n",
      "missed node 6_16 division completely\n",
      "missed node 10_13 division completely\n",
      "missed node 11_68 division completely\n",
      "missed node 13_10 division completely\n",
      "missed node 23_66 division completely\n",
      "missed node 24_11 division completely\n",
      "missed node 27_14 division completely\n",
      "missed node 28_16 division completely\n",
      "missed node 32_35 division completely\n",
      "missed node 35_23 division completely\n",
      "missed node 41_4 division completely\n",
      "missed node 43_8 division completely\n",
      "missed node 48_6 division completely\n",
      "missed node 49_41 division completely\n",
      "missed node 50_40 division completely\n",
      "missed node 53_11 division completely\n",
      "missed node 56_4 division completely\n",
      "missed node 57_10 division completely\n",
      "missed node 58_36 division completely\n",
      "missed node 60_0 division completely\n",
      "missed node 6_36 division completely\n",
      "missed node 12_10 division completely\n",
      "------ Fluo-N2DH-GOWT1 ------\n",
      "missed node 14_10 division completely\n",
      "missed node 17_24 division completely\n",
      "missed node 18_9 division completely\n",
      "missed node 21_42 division completely\n",
      "missed node 25_36 division completely\n",
      "missed node 37_35 division completely\n",
      "missed node 38_5 division completely\n",
      "missed node 41_26 division completely\n",
      "missed node 43_4 division completely\n",
      "missed node 46_35 division completely\n",
      "missed node 49_6 division completely\n",
      "missed node 50_42 division completely\n",
      "missed node 54_28 division completely\n",
      "missed node 57_12 division completely\n",
      "missed node 73_5 division completely\n",
      "missed node 21_19 division completely\n",
      "missed node 5_6 division completely\n",
      "missed node 10_66 division completely\n",
      "missed node 15_66 division completely\n",
      "missed node 16_9 division completely\n",
      "missed node 22_56 division completely\n",
      "missed node 25_57 division completely\n",
      "missed node 26_3 division completely\n",
      "missed node 28_39 division completely\n",
      "missed node 30_37 division completely\n",
      "missed node 35_52 division completely\n",
      "missed node 48_44 division completely\n",
      "missed node 51_28 division completely\n",
      "missed node 54_2 division completely\n",
      "missed node 55_27 division completely\n",
      "missed node 57_49 division completely\n",
      "missed node 62_3 division completely\n",
      "missed node 63_2 division completely\n",
      "missed node 66_12 division completely\n",
      "missed node 67_40 division completely\n",
      "missed node 70_52 division completely\n",
      "missed node 74_47 division completely\n",
      "missed node 76_44 division completely\n",
      "missed node 78_45 division completely\n",
      "missed node 80_61 division completely\n",
      "missed node 86_7 division completely\n",
      "missed node 88_27 division completely\n",
      "missed node 93_10 division completely\n",
      "missed node 94_36 division completely\n",
      "missed node 95_52 division completely\n",
      "missed node 97_60 division completely\n",
      "missed node 103_4 division completely\n",
      "missed node 104_34 division completely\n",
      "missed node 112_6 division completely\n",
      "missed node 115_45 division completely\n",
      "missed node 118_0 division completely\n",
      "missed node 121_42 division completely\n",
      "missed node 124_21 division completely\n",
      "missed node 125_22 division completely\n",
      "missed node 126_61 division completely\n",
      "missed node 127_51 division completely\n",
      "missed node 128_43 division completely\n",
      "missed node 132_23 division completely\n",
      "missed node 133_24 division completely\n",
      "missed node 135_25 division completely\n",
      "missed node 140_10 division completely\n",
      "missed node 141_35 division completely\n",
      "missed node 142_17 division completely\n",
      "missed node 144_28 division completely\n",
      "missed node 147_33 division completely\n",
      "missed node 148_59 division completely\n",
      "missed node 150_40 division completely\n",
      "missed node 152_62 division completely\n",
      "missed node 160_64 division completely\n",
      "missed node 163_66 division completely\n",
      "missed node 167_7 division completely\n",
      "missed node 179_68 division completely\n",
      "missed node 185_49 division completely\n",
      "missed node 1_29 division completely\n",
      "missed node 3_23 division completely\n",
      "missed node 11_22 division completely\n",
      "missed node 17_16 division completely\n",
      "missed node 20_38 division completely\n",
      "missed node 29_29 division completely\n",
      "missed node 38_34 division completely\n",
      "missed node 47_17 division completely\n",
      "Issue with 012\n",
      "missed node 1_48 division completely\n",
      "missed node 9_28 division completely\n",
      "missed node 21_34 division completely\n",
      "missed node 26_25 division completely\n",
      "Issue with 010\n",
      "missed node 2_37 division completely\n",
      "missed node 6_16 division completely\n",
      "missed node 10_13 division completely\n",
      "missed node 11_68 division completely\n",
      "missed node 13_10 division completely\n",
      "missed node 23_66 division completely\n",
      "missed node 24_11 division completely\n",
      "missed node 27_14 division completely\n",
      "missed node 28_16 division completely\n",
      "missed node 32_35 division completely\n",
      "missed node 35_23 division completely\n",
      "missed node 41_4 division completely\n",
      "missed node 43_8 division completely\n",
      "missed node 48_6 division completely\n",
      "missed node 49_41 division completely\n",
      "missed node 50_40 division completely\n",
      "missed node 53_11 division completely\n",
      "missed node 56_4 division completely\n",
      "missed node 57_10 division completely\n",
      "missed node 58_36 division completely\n",
      "missed node 60_0 division completely\n",
      "missed node 6_36 division completely\n",
      "missed node 12_10 division completely\n",
      "------ Fluo-N2DL-HeLa ------\n",
      "missed node 17_24 division completely\n",
      "missed node 18_9 division completely\n",
      "missed node 21_42 division completely\n",
      "missed node 37_35 division completely\n",
      "missed node 41_26 division completely\n",
      "missed node 43_4 division completely\n",
      "missed node 54_28 division completely\n",
      "missed node 73_5 division completely\n",
      "missed node 15_66 division completely\n",
      "missed node 30_37 division completely\n",
      "55_27 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 104_34 division completely\n",
      "missed node 118_0 division completely\n",
      "missed node 128_43 division completely\n",
      "missed node 140_10 division completely\n",
      "missed node 148_59 division completely\n",
      "missed node 160_64 division completely\n",
      "missed node 1_29 division completely\n",
      "missed node 3_23 division completely\n",
      "6_17 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "8_18 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 10_19 division completely\n",
      "missed node 15_17 division completely\n",
      "missed node 22_5 division completely\n",
      "missed node 29_17 division completely\n",
      "missed node 59_10 division completely\n",
      "missed node 60_34 division completely\n",
      "missed node 76_7 division completely\n",
      "missed node 77_16 division completely\n",
      "missed node 79_9 division completely\n",
      "missed node 83_18 division completely\n",
      "1_48 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 26_25 division completely\n",
      "missed node 4_26 division completely\n",
      "missed node 5_53 division completely\n",
      "missed node 9_38 division completely\n",
      "16_30 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 21_36 division completely\n",
      "missed node 22_24 division completely\n",
      "26_43 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 38_31 division completely\n",
      "missed node 39_57 division completely\n",
      "missed node 42_38 division completely\n",
      "47_32 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "missed node 68_23 division completely\n",
      "missed node 71_18 division completely\n",
      "missed node 79_28 division completely\n",
      "missed node 86_26 division completely\n",
      "missed node 91_51 division completely\n",
      "missed node 101_18 division completely\n",
      "missed node 110_19 division completely\n",
      "missed node 122_36 division completely\n",
      "missed node 123_38 division completely\n",
      "missed node 48_6 division completely\n",
      "missed node 49_41 division completely\n",
      "missed node 57_10 division completely\n",
      "missed node 60_0 division completely\n"
     ]
    }
   ],
   "source": [
    "benchmarks = []\n",
    "\n",
    "for m in [d for d in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, d))]:\n",
    "    print(f'------ {m} ------')\n",
    "    res_subdir = os.path.join(results_dir, m)\n",
    "\n",
    "    for data_id in data_ids:\n",
    "        gt_dir = os.path.join(data_dir, f'{data_id}_GT/TRA')\n",
    "        res_dir = os.path.join(res_subdir, f'{data_id}_RES')\n",
    "\n",
    "        try:\n",
    "            metrics = TrackingMetrics.from_isbi_dirs(gt_dir, res_dir)\n",
    "            benchmarks.append({\n",
    "                'model': m,\n",
    "                'data_id': data_id,\n",
    "                **metrics.stats\n",
    "            })\n",
    "        except ValueError:\n",
    "            print('Issue with', data_id)\n",
    "        \n",
    "df = pd.DataFrame(benchmarks)\n",
    "df.to_csv('benchmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
